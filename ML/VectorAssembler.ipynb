{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sc = SparkSession .builder\\\n",
    "        .appName(\"PCA\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.read.csv(\"Glass.data\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+----+----+-----+----+----+----+----+-----+\n",
      "|index|     RI|   Na|  Mg|  Al|   Si|   K|  Ca|  Ba|  Fe|Class|\n",
      "+-----+-------+-----+----+----+-----+----+----+----+----+-----+\n",
      "|    1|1.52101|13.64|4.49|1.10|71.78|0.06|8.75|0.00|0.00|    1|\n",
      "|    2|1.51761|13.89|3.60|1.36|72.73|0.48|7.83|0.00|0.00|    1|\n",
      "|    3|1.51618|13.53|3.55|1.54|72.99|0.39|7.78|0.00|0.00|    1|\n",
      "|    4|1.51766|13.21|3.69|1.29|72.61|0.57|8.22|0.00|0.00|    1|\n",
      "|    5|1.51742|13.27|3.62|1.24|73.08|0.55|8.07|0.00|0.00|    1|\n",
      "|    6|1.51596|12.79|3.61|1.62|72.97|0.64|8.07|0.00|0.26|    1|\n",
      "|    7|1.51743|13.30|3.60|1.14|73.09|0.58|8.17|0.00|0.00|    1|\n",
      "|    8|1.51756|13.15|3.61|1.05|73.24|0.57|8.24|0.00|0.00|    1|\n",
      "|    9|1.51918|14.04|3.58|1.37|72.08|0.56|8.30|0.00|0.00|    1|\n",
      "|   10|1.51755|13.00|3.60|1.36|72.99|0.57|8.40|0.00|0.11|    1|\n",
      "|   11|1.51571|12.72|3.46|1.56|73.20|0.67|8.09|0.00|0.24|    1|\n",
      "|   12|1.51763|12.80|3.66|1.27|73.01|0.60|8.56|0.00|0.00|    1|\n",
      "|   13|1.51589|12.88|3.43|1.40|73.28|0.69|8.05|0.00|0.24|    1|\n",
      "|   14|1.51748|12.86|3.56|1.27|73.21|0.54|8.38|0.00|0.17|    1|\n",
      "|   15|1.51763|12.61|3.59|1.31|73.29|0.58|8.50|0.00|0.00|    1|\n",
      "|   16|1.51761|12.81|3.54|1.23|73.24|0.58|8.39|0.00|0.00|    1|\n",
      "|   17|1.51784|12.68|3.67|1.16|73.11|0.61|8.70|0.00|0.00|    1|\n",
      "|   18|1.52196|14.36|3.85|0.89|71.36|0.15|9.15|0.00|0.00|    1|\n",
      "|   19|1.51911|13.90|3.73|1.18|72.12|0.06|8.89|0.00|0.00|    1|\n",
      "|   20|1.51735|13.02|3.54|1.69|72.73|0.54|8.44|0.00|0.07|    1|\n",
      "+-----+-------+-----+----+----+-----+----+----+----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- RI: string (nullable = true)\n",
      " |-- Na: string (nullable = true)\n",
      " |-- Mg: string (nullable = true)\n",
      " |-- Al: string (nullable = true)\n",
      " |-- Si: string (nullable = true)\n",
      " |-- K: string (nullable = true)\n",
      " |-- Ca: string (nullable = true)\n",
      " |-- Ba: string (nullable = true)\n",
      " |-- Fe: string (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert datatype of columns from string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "new_data = df.select(*(col(c).cast(\"float\").alias(c) for c in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: float (nullable = true)\n",
      " |-- RI: float (nullable = true)\n",
      " |-- Na: float (nullable = true)\n",
      " |-- Mg: float (nullable = true)\n",
      " |-- Al: float (nullable = true)\n",
      " |-- Si: float (nullable = true)\n",
      " |-- K: float (nullable = true)\n",
      " |-- Ca: float (nullable = true)\n",
      " |-- Ba: float (nullable = true)\n",
      " |-- Fe: float (nullable = true)\n",
      " |-- Class: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = new_data.drop('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=features.columns,\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|Class|\n",
      "+--------------------+-----+\n",
      "|[1.0,1.5210100412...|  1.0|\n",
      "|[2.0,1.5176099538...|  1.0|\n",
      "|[3.0,1.5161800384...|  1.0|\n",
      "|[4.0,1.5176600217...|  1.0|\n",
      "|[5.0,1.5174200534...|  1.0|\n",
      "|[6.0,1.5159599781...|  1.0|\n",
      "|[7.0,1.5174299478...|  1.0|\n",
      "|[8.0,1.5175600051...|  1.0|\n",
      "|[9.0,1.5191800594...|  1.0|\n",
      "|[10.0,1.517549991...|  1.0|\n",
      "|[11.0,1.515709996...|  1.0|\n",
      "|[12.0,1.517629981...|  1.0|\n",
      "|[13.0,1.515890002...|  1.0|\n",
      "|[14.0,1.517480015...|  1.0|\n",
      "|[15.0,1.517629981...|  1.0|\n",
      "|[16.0,1.517609953...|  1.0|\n",
      "|[17.0,1.517840027...|  1.0|\n",
      "|[18.0,1.521960020...|  1.0|\n",
      "|[19.0,1.519109964...|  1.0|\n",
      "|[20.0,1.517349958...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"features\", \"Class\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
