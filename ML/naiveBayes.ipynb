{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"NaiveBayes\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"diabetes.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|     88|  31|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0|   0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|      0|  38|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|      0|  30|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- Glucose: string (nullable = true)\n",
      " |-- BloodPressure: string (nullable = true)\n",
      " |-- SkinThickness: string (nullable = true)\n",
      " |-- Insulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Outcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "new_data = dataset.select(*(col(c).cast(\"float\").alias(c) for c in dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: float (nullable = true)\n",
      " |-- Glucose: float (nullable = true)\n",
      " |-- BloodPressure: float (nullable = true)\n",
      " |-- SkinThickness: float (nullable = true)\n",
      " |-- Insulin: float (nullable = true)\n",
      " |-- BMI: float (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: float (nullable = true)\n",
      " |-- Age: float (nullable = true)\n",
      " |-- Outcome: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|          0|      0|            0|            0|      0|  0|                       0|  0|      0|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "#checking for null ir nan type values in our columns\n",
    "new_data.select([count(when(col(c).isNull(), c)).alias(c) for c in new_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=new_data.columns\n",
    "cols.remove(\"Outcome\")\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "# Now let us use the transform method to transform our dataset\n",
    "data=assembler.transform(new_data)\n",
    "data = data.select(\"features\",'Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes(featuresCol='features',labelCol='Outcome',smoothing=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naive_bayes.fit(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select example rows to display.\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|            features|Outcome|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|(8,[0,1,6,7],[2.0...|    0.0|[-143.83567904225...|[0.34076013715848...|       1.0|\n",
      "|(8,[0,1,6,7],[10....|    1.0|[-246.02480623093...|[0.04183600349677...|       1.0|\n",
      "|(8,[1,5,6,7],[119...|    1.0|[-266.73892610504...|[0.74238623745696...|       0.0|\n",
      "|(8,[1,5,6,7],[145...|    1.0|[-343.41841982861...|[0.82114305732646...|       0.0|\n",
      "|(8,[1,5,6,7],[167...|    1.0|[-338.19925421681...|[0.54292199945573...|       0.0|\n",
      "|(8,[1,6,7],[94.0,...|    0.0|[-164.71757704226...|[0.36543019856782...|       1.0|\n",
      "|[0.0,67.0,76.0,0....|    0.0|[-412.92025298417...|[0.99999996307298...|       0.0|\n",
      "|[0.0,86.0,68.0,32...|    0.0|[-439.28761904950...|[0.99999999530970...|       0.0|\n",
      "|[0.0,95.0,64.0,39...|    0.0|[-643.27046136234...|[0.70105869360027...|       0.0|\n",
      "|[0.0,100.0,70.0,2...|    0.0|[-500.93337976918...|[0.99982353897980...|       0.0|\n",
      "|[0.0,101.0,62.0,0...|    0.0|[-323.58026657488...|[0.99999036937813...|       0.0|\n",
      "|[0.0,101.0,65.0,2...|    0.0|[-405.90231372628...|[0.99999994836850...|       0.0|\n",
      "|[0.0,102.0,52.0,0...|    0.0|[-305.36014603767...|[0.99994813198972...|       0.0|\n",
      "|[0.0,102.0,64.0,4...|    0.0|[-616.97576390248...|[0.99841582593436...|       0.0|\n",
      "|[0.0,102.0,86.0,1...|    0.0|[-601.21818246979...|[0.50169815766036...|       0.0|\n",
      "|[0.0,104.0,64.0,2...|    0.0|[-588.22587778505...|[0.00599452695857...|       1.0|\n",
      "|[0.0,104.0,64.0,3...|    1.0|[-557.41595613921...|[0.99910053164605...|       0.0|\n",
      "|[0.0,105.0,84.0,0...|    1.0|[-467.19476490984...|[0.99999995952290...|       0.0|\n",
      "|[0.0,107.0,62.0,3...|    1.0|[-569.54193004922...|[0.98083692540801...|       0.0|\n",
      "|[0.0,113.0,80.0,1...|    0.0|[-426.28320852481...|[0.99999997552174...|       0.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.589041095890411\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
